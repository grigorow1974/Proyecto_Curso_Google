{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACE stages\n",
    "Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute.\n",
    "\n",
    "\n",
    "PACE: Plan\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Plan stage.\n",
    "\n",
    "In this stage, consider the following questions:\n",
    "\n",
    "What are you being asked to do?\n",
    "What are the ethical implications of the model? What are the consequences of your model making errors?\n",
    "\n",
    "What is the likely effect of the model when it predicts a false negative (i.e., when the model says a customer will give a tip, but they actually won't)?\n",
    "\n",
    "What is the likely effect of the model when it predicts a false positive (i.e., when the model says a customer will not give a tip, but they actually will)?\n",
    "\n",
    "Do the benefits of such a model outweigh the potential problems?\n",
    "\n",
    "Would you proceed with the request to build this model? Why or why not?\n",
    "\n",
    "Can the objective be modified to make it less problematic?\n",
    "\n",
    "Exemplar responses:\n",
    "\n",
    "Question 1:\n",
    "\n",
    "Predict if a customer will not leave a tip.\n",
    "\n",
    "Question 2:\n",
    "\n",
    "Drivers who didn't receive tips will probably be upset that the app told them a customer would leave a tip. If it happened often, drivers might not trust the app. Drivers are unlikely to pick up people who are predicted to not leave tips. Customers will have difficulty finding a taxi that will pick them up, and might get angry at the taxi company. Even when the model is correct, people who can't afford to tip will find it more difficult to get taxis, which limits the accessibility of taxi service to those who pay extra.\n",
    "\n",
    "Question 3:\n",
    "\n",
    "It's not good to disincentivize drivers from picking up customers. It could also cause a customer backlash. The problems seem to outweigh the benefits.\n",
    "\n",
    "Question 4:\n",
    "\n",
    "No. Effectively limiting equal access to taxis is ethically problematic, and carries a lot of risk.\n",
    "\n",
    "Question 5:\n",
    "\n",
    "We can build a model that predicts the most generous customers. This could accomplish the goal of helping taxi drivers increase their earnings from tips while preventing the wrongful exclusion of certain people from using taxis.\n",
    "\n",
    "Suppose you were to modify the modeling objective so, instead of predicting people who won't tip at all, you predicted people who are particularly generous—those who will tip 20% or more? Consider the following questions:\n",
    "\n",
    "Exemplar responses:\n",
    "\n",
    "Question 1: What features do you need to make this prediction?\n",
    "\n",
    "Ideally, we'd have behavioral history for each customer, so we could know how much they tipped on previous taxi rides. We'd also want times, dates, and locations of both pickups and dropoffs, estimated fares, and payment method.\n",
    "\n",
    "Question 2: What would be the target variable?\n",
    "\n",
    "The target variable would be a binary variable (1 or 0) that indicates whether or not the customer is expected to tip ≥ 20%.\n",
    "\n",
    "Question 3:\n",
    "\n",
    "This is a supervised learning, classification task. We could use accuracy, precision, recall, F-score, area under the ROC curve, or a number of other metrics. However, we don't have enough information at this time to know which are most appropriate. We need to know the class balance of the target variable.\n",
    "\n",
    "Complete the following steps to begin:\n",
    "\n",
    "Task 1. Imports and data loading\n",
    "Import packages and libraries needed to build and evaluate random forest and XGBoost classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# This is the function that helps plot feature importance \n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_preds_means = pd.read_csv('nyc_preds_means.csv')\n",
    "df0 = pd.read_csv('C:../data/raw/2017_Yellow_Taxi_Trip_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30841670</td>\n",
       "      <td>2</td>\n",
       "      <td>04/15/2017 11:32:20 PM</td>\n",
       "      <td>04/15/2017 11:49:03 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  \\\n",
       "0    24870114         2   03/25/2017 8:55:43 AM   03/25/2017 9:09:47 AM   \n",
       "1    35634249         1   04/11/2017 2:53:28 PM   04/11/2017 3:19:58 PM   \n",
       "2   106203690         1   12/15/2017 7:26:56 AM   12/15/2017 7:34:08 AM   \n",
       "3    38942136         2   05/07/2017 1:17:59 PM   05/07/2017 1:48:14 PM   \n",
       "4    30841670         2  04/15/2017 11:32:20 PM  04/15/2017 11:49:03 PM   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "4                1           4.37           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "4             4           112             2         16.5    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \n",
       "0        2.76           0.0                    0.3         16.56  \n",
       "1        4.00           0.0                    0.3         20.80  \n",
       "2        1.45           0.0                    0.3          8.75  \n",
       "3        6.39           0.0                    0.3         27.69  \n",
       "4        0.00           0.0                    0.3         17.80  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.616667</td>\n",
       "      <td>4.435000</td>\n",
       "      <td>15.845642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_duration  mean_distance  predicted_fare\n",
       "0      22.847222       3.521667       16.434245\n",
       "1      24.470370       3.108889       16.052218\n",
       "2       7.250000       0.881429        7.053706\n",
       "3      30.250000       3.700000       18.731650\n",
       "4      14.616667       4.435000       15.845642"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_preds_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30841670</td>\n",
       "      <td>2</td>\n",
       "      <td>04/15/2017 11:32:20 PM</td>\n",
       "      <td>04/15/2017 11:49:03 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "      <td>14.616667</td>\n",
       "      <td>4.435000</td>\n",
       "      <td>15.845642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  \\\n",
       "0    24870114         2   03/25/2017 8:55:43 AM   03/25/2017 9:09:47 AM   \n",
       "1    35634249         1   04/11/2017 2:53:28 PM   04/11/2017 3:19:58 PM   \n",
       "2   106203690         1   12/15/2017 7:26:56 AM   12/15/2017 7:34:08 AM   \n",
       "3    38942136         2   05/07/2017 1:17:59 PM   05/07/2017 1:48:14 PM   \n",
       "4    30841670         2  04/15/2017 11:32:20 PM  04/15/2017 11:49:03 PM   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "4                1           4.37           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "4             4           112             2         16.5    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        2.76           0.0                    0.3         16.56   \n",
       "1        4.00           0.0                    0.3         20.80   \n",
       "2        1.45           0.0                    0.3          8.75   \n",
       "3        6.39           0.0                    0.3         27.69   \n",
       "4        0.00           0.0                    0.3         17.80   \n",
       "\n",
       "   mean_duration  mean_distance  predicted_fare  \n",
       "0      22.847222       3.521667       16.434245  \n",
       "1      24.470370       3.108889       16.052218  \n",
       "2       7.250000       0.881429        7.053706  \n",
       "3      30.250000       3.700000       18.731650  \n",
       "4      14.616667       4.435000       15.845642  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge datasets\n",
    "df0 = df0.merge(nyc_preds_means,\n",
    "                left_index=True,\n",
    "                right_index=True)\n",
    "\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PACE: Analyze\n",
    "Consider the questions in your PACE Strategy Documentto reflect on the Analyze stage.\n",
    "\n",
    "Task 2. Feature engineering\n",
    "You have already prepared much of this data and performed exploratory data analysis (EDA) in previous courses.\n",
    "\n",
    "Call info() on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22699 entries, 0 to 22698\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             22699 non-null  int64  \n",
      " 1   VendorID               22699 non-null  int64  \n",
      " 2   tpep_pickup_datetime   22699 non-null  object \n",
      " 3   tpep_dropoff_datetime  22699 non-null  object \n",
      " 4   passenger_count        22699 non-null  int64  \n",
      " 5   trip_distance          22699 non-null  float64\n",
      " 6   RatecodeID             22699 non-null  int64  \n",
      " 7   store_and_fwd_flag     22699 non-null  object \n",
      " 8   PULocationID           22699 non-null  int64  \n",
      " 9   DOLocationID           22699 non-null  int64  \n",
      " 10  payment_type           22699 non-null  int64  \n",
      " 11  fare_amount            22699 non-null  float64\n",
      " 12  extra                  22699 non-null  float64\n",
      " 13  mta_tax                22699 non-null  float64\n",
      " 14  tip_amount             22699 non-null  float64\n",
      " 15  tolls_amount           22699 non-null  float64\n",
      " 16  improvement_surcharge  22699 non-null  float64\n",
      " 17  total_amount           22699 non-null  float64\n",
      " 18  mean_duration          22699 non-null  float64\n",
      " 19  mean_distance          22699 non-null  float64\n",
      " 20  predicted_fare         22699 non-null  float64\n",
      "dtypes: float64(11), int64(7), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know from your EDA that customers who pay cash generally have a tip amount of $0. To meet the modeling objective, you'll need to sample the data to select only the customers who pay with credit card.\n",
    "\n",
    "Copy df0 and assign the result to a variable called df1. Then, use a Boolean mask to filter df1 so it contains only customers who paid with credit card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to isolate only customers who paid by credit card\n",
    "df1 = df0[df0['payment_type']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target\n",
    "Notice that there isn't a column that indicates tip percent, which is what you need to create the target variable. You'll have to engineer it.\n",
    "\n",
    "Add a tip_percent column to the dataframe by performing the following calculation:\n",
    "\n",
    "𝑡𝑖𝑝 𝑝𝑒𝑟𝑐𝑒𝑛𝑡=𝑡𝑖𝑝 𝑎𝑚𝑜𝑢𝑛𝑡𝑡𝑜𝑡𝑎𝑙 𝑎𝑚𝑜𝑢𝑛𝑡−𝑡𝑖𝑝 𝑎𝑚𝑜𝑢𝑛𝑡\n",
    " \n",
    "Round the result to three places beyond the decimal. This is an important step. It affects how many customers are labeled as generous tippers. In fact, without performing this step, approximately 1,800 people who do tip ≥ 20% would be labeled as not generous.\n",
    "\n",
    "To understand why, you must consider how floats work. Computers make their calculations using floating-point arithmetic (hence the word \"float\"). Floating-point arithmetic is a system that allows computers to express both very large numbers and very small numbers with a high degree of precision, encoded in binary. However, precision is limited by the number of bits used to represent a number, which is generally 32 or 64, depending on the capabilities of your operating system.\n",
    "\n",
    "This comes with limitations in that sometimes calculations that should result in clean, precise values end up being encoded as very long decimals. Take, for example, the following calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tip % col\n",
    "df0['tip_percent'] = round(df0['tip_amount'] / (df0['total_amount'] - df0['tip_amount']), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'generous' col (target)\n",
    "df0['generous'] = df0['tip_percent']\n",
    "df0['generous'] = (df0['generous'] >= 0.2)\n",
    "df0['generous'] = df0['generous'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pickup and dropoff cols to datetime\n",
    "df0['tpep_pickup_datetime'] = pd.to_datetime(df0['tpep_pickup_datetime'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "df0['tpep_dropoff_datetime'] = pd.to_datetime(df0['tpep_dropoff_datetime'], format='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'day' col\n",
    "df0['day'] = df0['tpep_pickup_datetime'].dt.day_name().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'am_rush' col\n",
    "df0['am_rush'] = df0['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Create 'daytime' col\n",
    "df0['daytime'] = df0['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Create 'pm_rush' col\n",
    "df0['pm_rush'] = df0['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Create 'nighttime' col\n",
    "df0['nighttime'] = df0['tpep_pickup_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'am_rush()' conversion function [06:00–10:00)\n",
    "def am_rush(hour):\n",
    "    if 6 <= hour['am_rush'] < 10:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: am_rush, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply 'am_rush' function to the 'am_rush' series\n",
    "df0['am_rush'] = df0.apply(am_rush, axis=1)\n",
    "df0['am_rush'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'daytime()' conversion function [10:00–16:00)\n",
    "def daytime(hour):\n",
    "    if 10 <= hour['daytime'] < 16:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply 'daytime' function to the 'daytime' series\n",
    "df0['daytime'] = df0.apply(daytime, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'pm_rush()' conversion function [16:00–20:00)\n",
    "def pm_rush(hour):\n",
    "    if 16 <= hour['pm_rush'] < 20:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply 'pm_rush' function to the 'pm_rush' series\n",
    "df0['pm_rush'] = df0.apply(pm_rush, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'nighttime()' conversion function [20:00–06:00)\n",
    "def nighttime(hour):\n",
    "    if 20 <= hour['nighttime'] < 24:\n",
    "        val = 1\n",
    "    elif 0 <= hour['nighttime'] < 6:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply 'nighttime' function to the 'nighttime' series\n",
    "df0['nighttime'] = df0.apply(nighttime, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'month' col\n",
    "df0['month'] = df0['tpep_pickup_datetime'].dt.strftime('%b').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22699 entries, 0 to 22698\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   VendorID         22699 non-null  int64  \n",
      " 1   passenger_count  22699 non-null  int64  \n",
      " 2   RatecodeID       22699 non-null  int64  \n",
      " 3   PULocationID     22699 non-null  int64  \n",
      " 4   DOLocationID     22699 non-null  int64  \n",
      " 5   mean_duration    22699 non-null  float64\n",
      " 6   mean_distance    22699 non-null  float64\n",
      " 7   predicted_fare   22699 non-null  float64\n",
      " 8   generous         22699 non-null  int32  \n",
      " 9   day              22699 non-null  object \n",
      " 10  am_rush          22699 non-null  int64  \n",
      " 11  daytime          22699 non-null  int64  \n",
      " 12  pm_rush          22699 non-null  int64  \n",
      " 13  nighttime        22699 non-null  int64  \n",
      " 14  month            22699 non-null  object \n",
      "dtypes: float64(3), int32(1), int64(9), object(2)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop columns\n",
    "drop_cols = ['Unnamed: 0', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "             'payment_type', 'trip_distance', 'store_and_fwd_flag', 'payment_type',\n",
    "             'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "             'improvement_surcharge', 'total_amount', 'tip_percent']\n",
    "\n",
    "df0 = df0.drop(drop_cols, axis=1)\n",
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define list of cols to convert to string\n",
    "cols_to_str = ['RatecodeID', 'PULocationID', 'DOLocationID', 'VendorID']\n",
    "\n",
    "# 2. Convert each column to string\n",
    "for col in cols_to_str:\n",
    "    df0[col] = df0[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22699 entries, 0 to 22698\n",
      "Columns: 398 entries, passenger_count to month_sep\n",
      "dtypes: bool(389), float64(3), int32(1), int64(5)\n",
      "memory usage: 9.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert categoricals to binary\n",
    "df2 = pd.get_dummies(df0, drop_first=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generous\n",
       "0    0.64602\n",
       "1    0.35398\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class balance of 'generous' col\n",
    "df2['generous'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate target variable (y)\n",
    "y = df2['generous']\n",
    "\n",
    "# Isolate the features (X)\n",
    "X = df2.drop('generous', axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest\n",
    "Begin with using GridSearchCV to tune a random forest model.\n",
    "\n",
    "Instantiate the random forest classifier rf and set the random state.\n",
    "\n",
    "Create a dictionary cv_params of any of the following hyperparameters and their corresponding values to tune. The more you tune, the better your model will fit the data, but the longer it will take.\n",
    "\n",
    "max_depth\n",
    "max_features\n",
    "max_samples\n",
    "min_samples_leaf\n",
    "min_samples_split\n",
    "n_estimators\n",
    "Define a set scoring of scoring metrics for GridSearch to capture (precision, recall, F1 score, and accuracy).\n",
    "\n",
    "Instantiate the GridSearchCV object rf1. Pass to it as arguments:\n",
    "\n",
    "estimator=rf\n",
    "param_grid=cv_params\n",
    "scoring=scoring\n",
    "cv: define the number of you cross-validation folds you want (cv=_)\n",
    "refit: indicate which evaluation metric you want to use to select the model (refit=_)\n",
    "Note: refit should be set to 'f1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m scoring \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 4. Instantiate the GridSearchCV object\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m rf1 \u001b[38;5;241m=\u001b[39m GridSearchCV(rf, cv_params, scoring\u001b[38;5;241m=\u001b[39m\u001b[43macuracy_score\u001b[49m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'acuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune \n",
    "# Note that this example only contains 1 value for each parameter for simplicity,\n",
    "# but you should assign a dictionary with ranges of values\n",
    "cv_params = {'max_depth': [None],\n",
    "             'max_features': [1.0],\n",
    "             'max_samples': [0.7],\n",
    "             'min_samples_leaf': [1],\n",
    "             'min_samples_split': [2],\n",
    "             'n_estimators': [300]\n",
    "             }\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1'}\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "rf1 = GridSearchCV(rf, cv_params, scoring=acuracy_score, cv=4, refit='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'scoring' parameter of GridSearchCV must be a str among {'accuracy', 'max_error', 'balanced_accuracy', 'jaccard_weighted', 'roc_auc_ovo', 'adjusted_mutual_info_score', 'jaccard_macro', 'neg_brier_score', 'neg_mean_gamma_deviance', 'neg_mean_absolute_error', 'f1_micro', 'f1_samples', 'matthews_corrcoef', 'mutual_info_score', 'precision_micro', 'roc_auc_ovo_weighted', 'neg_median_absolute_error', 'f1_weighted', 'recall_macro', 'neg_root_mean_squared_log_error', 'explained_variance', 'neg_mean_squared_error', 'roc_auc_ovr', 'normalized_mutual_info_score', 'precision_weighted', 'top_k_accuracy', 'jaccard', 'precision_samples', 'recall', 'fowlkes_mallows_score', 'v_measure_score', 'average_precision', 'recall_samples', 'neg_mean_squared_log_error', 'completeness_score', 'neg_mean_absolute_percentage_error', 'recall_weighted', 'rand_score', 'f1', 'positive_likelihood_ratio', 'jaccard_samples', 'r2', 'precision', 'precision_macro', 'roc_auc_ovr_weighted', 'jaccard_micro', 'neg_root_mean_squared_error', 'adjusted_rand_score', 'f1_macro', 'roc_auc', 'neg_mean_poisson_deviance', 'recall_micro', 'neg_negative_likelihood_ratio', 'homogeneity_score', 'neg_log_loss'}, a callable, an instance of 'list', an instance of 'tuple', an instance of 'dict' or None. Got {'accuracy', 'recall', 'f1', 'precision'} instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1467\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1462\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1463\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1464\u001b[0m )\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1467\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[0;32m   1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:666\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    659\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \n\u001b[0;32m    661\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'scoring' parameter of GridSearchCV must be a str among {'accuracy', 'max_error', 'balanced_accuracy', 'jaccard_weighted', 'roc_auc_ovo', 'adjusted_mutual_info_score', 'jaccard_macro', 'neg_brier_score', 'neg_mean_gamma_deviance', 'neg_mean_absolute_error', 'f1_micro', 'f1_samples', 'matthews_corrcoef', 'mutual_info_score', 'precision_micro', 'roc_auc_ovo_weighted', 'neg_median_absolute_error', 'f1_weighted', 'recall_macro', 'neg_root_mean_squared_log_error', 'explained_variance', 'neg_mean_squared_error', 'roc_auc_ovr', 'normalized_mutual_info_score', 'precision_weighted', 'top_k_accuracy', 'jaccard', 'precision_samples', 'recall', 'fowlkes_mallows_score', 'v_measure_score', 'average_precision', 'recall_samples', 'neg_mean_squared_log_error', 'completeness_score', 'neg_mean_absolute_percentage_error', 'recall_weighted', 'rand_score', 'f1', 'positive_likelihood_ratio', 'jaccard_samples', 'r2', 'precision', 'precision_macro', 'roc_auc_ovr_weighted', 'jaccard_micro', 'neg_root_mean_squared_error', 'adjusted_rand_score', 'f1_macro', 'roc_auc', 'neg_mean_poisson_deviance', 'recall_micro', 'neg_negative_likelihood_ratio', 'homogeneity_score', 'neg_log_loss'}, a callable, an instance of 'list', an instance of 'tuple', an instance of 'dict' or None. Got {'accuracy', 'recall', 'f1', 'precision'} instead."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
